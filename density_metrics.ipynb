{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to Augur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sqlalchemy as salc\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "database_connection_string = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(\n",
    "                              os.environ.get('PG_USER'),\n",
    "                              os.environ.get('PG_PASS'),\n",
    "                              os.environ.get('PG_HOST'),\n",
    "                              os.environ.get('PG_PORT'),\n",
    "                              os.environ.get('PG_DB')\n",
    "                            )\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = salc.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Metrics\n",
    "- SQL query for github activity metrics\n",
    "- Focused on the increment in activity (star/fork/watch/committer/commit/issue) over time to prevent from old repo having lots of accumulated activity.\n",
    "    -  Assigned different weights for #increase_in_stars, #increase_in_forks, #increase_in_watch, #increase_in_committer, #increase_in_commit, #increase_in_issue, #increase_in_pr, #increase_in_pr_open, #increase_in_pr_close, #increase_in_pr_merge, then sum them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.DataFrame()\n",
    "\n",
    "repo_query = salc.sql.text(f\"\"\"\n",
    "SELECT x.repo_id,\n",
    "       x.rg_name,\n",
    "       x.repo_name,\n",
    "       last_updated,\n",
    "       DATE(last_updated),\n",
    "       to_char(last_updated, 'DAY'),\n",
    "       EXTRACT(year FROM last_updated) AS \"Year\",\n",
    "       EXTRACT(month FROM last_updated) AS \"month\",\n",
    "       extract(hour from last_updated) AS \"hour\",\n",
    "       x.increase_committer,\n",
    "       x.increase_pr_open,\n",
    "       x.increase_commit,\n",
    "       (x.increase_committer + x.increase_pr_open + x.increase_pr_close + x.increase_pr_merge + x.increase_issue + x.increase_pr + x.increase_star + x.increase_fork)*10 AS total\n",
    "            FROM(\n",
    "        SELECT \n",
    "            rg.repo_group_id,\n",
    "            rg.rg_name,\n",
    "            r.repo_id,\n",
    "            r.repo_name,\n",
    "            /*ri.license,*/\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.stars_count - lag(ri.stars_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 0.01\n",
    "            END\n",
    "                AS increase_star,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.fork_count - lag(ri.fork_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 0.2\n",
    "            END\n",
    "                AS increase_fork,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.watchers_count - lag(ri.watchers_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 0.1\n",
    "            END\n",
    "                AS increase_watch,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.committers_count - lag(ri.committers_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) *1.6\n",
    "            END\n",
    "                AS increase_committer,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.commit_count - lag(ri.commit_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 1.3\n",
    "            END\n",
    "                AS increase_commit,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.issues_count - lag(ri.issues_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 0.5\n",
    "            END\n",
    "                AS increase_issue,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.pull_request_count - lag(ri.pull_request_count) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 1\n",
    "            END\n",
    "                AS increase_pr,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.pull_requests_open - lag(ri.pull_requests_open) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 1.2\n",
    "            END\n",
    "                AS increase_pr_open,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.pull_requests_closed - lag(ri.pull_requests_closed) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 1.5\n",
    "            END\n",
    "                AS increase_pr_close,\n",
    "            CASE\n",
    "                WHEN r.repo_id - lag(r.repo_id) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) = 0 THEN \n",
    "                (ri.pull_requests_merged - lag(ri.pull_requests_merged) over (order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated)) * 1.8    \n",
    "            END\n",
    "                AS increase_pr_merge,\n",
    "            ri.last_updated,\n",
    "            CASE\n",
    "                WHEN EXTRACT(YEAR FROM ri.last_updated) < 2022 THEN 'far away'\n",
    "                WHEN EXTRACT(YEAR FROM ri.last_updated) >= 2022 THEN 'recent'\n",
    "            END\n",
    "                AS segment,\n",
    "            EXTRACT(year FROM last_updated) AS \"Year\",\n",
    "            EXTRACT(month FROM last_updated) AS \"month\" \n",
    "        FROM REPO r\n",
    "            LEFT JOIN repo_groups rg\n",
    "            ON rg.repo_group_id = r.repo_group_id\n",
    "            LEFT join repo_info ri \n",
    "            on r.repo_id = ri.repo_id \n",
    "        /*where rg.rg_name = 'agroal'*/\n",
    "        order by rg.repo_group_id ASC, r.repo_id ASC, ri.last_updated) AS x\n",
    "\"\"\")\n",
    "\n",
    "dframe = pd.read_sql(repo_query, con=engine)\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NA value into zero\n",
    "dframe = dframe.fillna(0)\n",
    "# calculating activeness percentage based on org and repo_name\n",
    "df2 = dframe.groupby(['rg_name', 'repo_name']).agg({'total': 'sum'})\n",
    "df3 = df2.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "df4 = df3['total'].to_frame().reset_index()\n",
    "df4 = df4[df4['total'] != 0.0]\n",
    "df4.head()\n",
    "\n",
    "# extract column 'month' and 'percentage', copy it as another dataframe\n",
    "# dft = dtest[['month', 'percentage']].copy()\n",
    "# dft = dframe['percentage'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df4[df4['rg_name'] == 'openshift']\n",
    "t[t['repo_name'] == 'docker-distribution']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df4, x=\"rg_name\", y=\"total\", color=\"repo_name\", text=\"repo_name\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drepo = df4[df4['rg_name'] == 'kubernetes']\n",
    "\n",
    "import plotly.express as px\n",
    "fig_pie = px.pie(data_frame=drepo, names='repo_name', values='total')\n",
    "fig_pie.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
